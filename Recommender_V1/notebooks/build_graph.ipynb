{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5ef7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore/Recommender_V1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ff9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from srcs.utils.logger import get_module_logger\n",
    "\n",
    "NOTEBOOK_DIR = os.getcwd() \n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../\"))  \n",
    "\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from srcs.utils.settings import (\n",
    "    CLEANED_METADATA_PATH_CSV, CLEANED_REVIEWS_PATH_CSV, FULL_GRAPH_PATH,\n",
    "    TRAIN_GRAPH_PATH, VAL_GRAPH_PATH, TEST_GRAPH_PATH\n",
    ")\n",
    "\n",
    "\n",
    "# Set up the logger\n",
    "logger = get_module_logger(\"graph_builder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefd40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # Importing matplotlib for plotting\n",
    "\n",
    "reviews_df = pd.read_csv(CLEANED_REVIEWS_PATH_CSV)\n",
    "meta_df = pd.read_csv(CLEANED_METADATA_PATH_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818e6ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>recency</th>\n",
       "      <th>recency_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>B0047T79VS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-08-08 06:08:03.000</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4650</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>B01HHURN3W</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2014-08-25 19:42:23.000</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>3903</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>B017T99JPG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-02-29 18:59:25.000</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>3350</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>B01LW71IBJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-02-29 19:02:51.000</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3350</td>\n",
       "      <td>0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGCI7FAH4GL5FI65HYLKWTMFZ2CQ</td>\n",
       "      <td>B09S6Y5BRG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-11-04 18:40:31.659</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>2371</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin  rating                timestamp  \\\n",
       "0  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ  B0047T79VS     3.0  2012-08-08 06:08:03.000   \n",
       "1  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ  B01HHURN3W     3.0  2014-08-25 19:42:23.000   \n",
       "2  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ  B017T99JPG     5.0  2016-02-29 18:59:25.000   \n",
       "3  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ  B01LW71IBJ     5.0  2016-02-29 19:02:51.000   \n",
       "4  AGCI7FAH4GL5FI65HYLKWTMFZ2CQ  B09S6Y5BRG     5.0  2018-11-04 18:40:31.659   \n",
       "\n",
       "   year  month  day  hour  minute  recency  recency_weight  \n",
       "0  2012      8    8     6       8     4650        0.000215  \n",
       "1  2014      8   25    19      42     3903        0.000256  \n",
       "2  2016      2   29    18      59     3350        0.000298  \n",
       "3  2016      2   29    19       2     3350        0.000298  \n",
       "4  2018     11    4    18      40     2371        0.000422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c488db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>price</th>\n",
       "      <th>store</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_description_items</th>\n",
       "      <th>first_image</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>date_first_available</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computers</td>\n",
       "      <td>Digi-Tatoo Decal Skin Compatible With MacBook ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>246</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Digi-Tatoo</td>\n",
       "      <td>B07SM135LS</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31t4bj9t88...</td>\n",
       "      <td>Digi-Tatoo</td>\n",
       "      <td>Fresh Marble</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon Fashion</td>\n",
       "      <td>NotoCity Compatible with Vivoactive 4 band 22m...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>233</td>\n",
       "      <td>9.99</td>\n",
       "      <td>Notocity</td>\n",
       "      <td>B089CNGZCW</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41j56fjX6S...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell Phones &amp; Accessories</td>\n",
       "      <td>Motorola Droid X Essentials Combo Pack</td>\n",
       "      <td>3.8</td>\n",
       "      <td>64</td>\n",
       "      <td>14.99</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>B004E2Z88O</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51-DXSMlHa...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2010-11-26</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cell Phones &amp; Accessories</td>\n",
       "      <td>QGHXO Band for Garmin Vivofit 4, Soft Silicone...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>707</td>\n",
       "      <td>14.89</td>\n",
       "      <td>Qghxo</td>\n",
       "      <td>B07BJ7ZZL7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51UefzXMzv...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5Pcs Bands-Girl</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cell Phones &amp; Accessories</td>\n",
       "      <td>May Chen Compatible with MacBook Pro 16 inch C...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>649</td>\n",
       "      <td>26.99</td>\n",
       "      <td>May Chen</td>\n",
       "      <td>B0822SL7JX</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mR3hFRLs...</td>\n",
       "      <td>May Chen</td>\n",
       "      <td>Abstract Leaves</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               main_category  \\\n",
       "0                  Computers   \n",
       "1             Amazon Fashion   \n",
       "2  Cell Phones & Accessories   \n",
       "3  Cell Phones & Accessories   \n",
       "4  Cell Phones & Accessories   \n",
       "\n",
       "                                               title  average_rating  \\\n",
       "0  Digi-Tatoo Decal Skin Compatible With MacBook ...             4.5   \n",
       "1  NotoCity Compatible with Vivoactive 4 band 22m...             4.5   \n",
       "2             Motorola Droid X Essentials Combo Pack             3.8   \n",
       "3  QGHXO Band for Garmin Vivofit 4, Soft Silicone...             4.4   \n",
       "4  May Chen Compatible with MacBook Pro 16 inch C...             4.5   \n",
       "\n",
       "   rating_number  price       store parent_asin  n_features  \\\n",
       "0            246  19.99  Digi-Tatoo  B07SM135LS           5   \n",
       "1            233   9.99    Notocity  B089CNGZCW           5   \n",
       "2             64  14.99     Verizon  B004E2Z88O           3   \n",
       "3            707  14.89       Qghxo  B07BJ7ZZL7           5   \n",
       "4            649  26.99    May Chen  B0822SL7JX           5   \n",
       "\n",
       "   n_description_items                                        first_image  \\\n",
       "0                    0  https://m.media-amazon.com/images/I/31t4bj9t88...   \n",
       "1                    0  https://m.media-amazon.com/images/I/41j56fjX6S...   \n",
       "2                    1  https://m.media-amazon.com/images/I/51-DXSMlHa...   \n",
       "3                   10  https://m.media-amazon.com/images/I/51UefzXMzv...   \n",
       "4                    1  https://m.media-amazon.com/images/I/51mR3hFRLs...   \n",
       "\n",
       "        brand            color date_first_available primary_category  \\\n",
       "0  Digi-Tatoo     Fresh Marble           2019-06-03      Electronics   \n",
       "1     Unknown          Unknown           2020-05-29      Electronics   \n",
       "2     Unknown          Unknown           2010-11-26      Electronics   \n",
       "3     Unknown  5Pcs Bands-Girl           2018-03-17      Electronics   \n",
       "4    May Chen  Abstract Leaves           2023-02-06      Electronics   \n",
       "\n",
       "  rating_bin  \n",
       "0     Medium  \n",
       "1     Medium  \n",
       "2     Medium  \n",
       "3     Medium  \n",
       "4     Medium  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3598d42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13472190, 13513)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_df), len(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb2e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both columns are strings\n",
    "reviews_df['parent_asin'] = reviews_df['parent_asin'].astype(str)\n",
    "meta_df['parent_asin'] = meta_df['parent_asin'].astype(str)\n",
    "\n",
    "# Keep only reviews for products that exist in meta_df\n",
    "filtered_reviews_df = reviews_df[reviews_df['parent_asin'].isin(meta_df['parent_asin'])].copy()\n",
    "\n",
    "# Optional: Keep only meta entries that appear in reviews (not mandatory unless needed)\n",
    "filtered_meta_df = meta_df[meta_df['parent_asin'].isin(filtered_reviews_df['parent_asin'])].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba6b5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered reviews: 1,138,185\n",
      "Unique products in reviews: 13,513\n",
      "Filtered meta products: 13,513\n"
     ]
    }
   ],
   "source": [
    "print(f\"Filtered reviews: {len(filtered_reviews_df):,}\")\n",
    "print(f\"Unique products in reviews: {filtered_reviews_df['parent_asin'].nunique():,}\")\n",
    "print(f\"Filtered meta products: {len(filtered_meta_df):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0f4cb",
   "metadata": {},
   "source": [
    "# Build the Bipartite Graph of Users ↔ Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b5ec956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['user_id', 'parent_asin', 'rating', 'timestamp', 'year', 'month', 'day',\n",
       "        'hour', 'minute', 'recency', 'recency_weight'],\n",
       "       dtype='object'),\n",
       " Index(['main_category', 'title', 'average_rating', 'rating_number', 'price',\n",
       "        'store', 'parent_asin', 'n_features', 'n_description_items',\n",
       "        'first_image', 'brand', 'color', 'date_first_available',\n",
       "        'primary_category', 'rating_bin'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_reviews_df.columns, filtered_meta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5fc26c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 742651, Num items: 13513, Total nodes: 756164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode users & items\n",
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "\n",
    "filtered_reviews_df['user_idx'] = user_enc.fit_transform(filtered_reviews_df['user_id'])\n",
    "filtered_reviews_df['item_idx'] = item_enc.fit_transform(filtered_reviews_df['parent_asin'])\n",
    "\n",
    "num_users = len(user_enc.classes_)\n",
    "num_items = len(item_enc.classes_)\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "print(f\"Num users: {num_users}, Num items: {num_items}, Total nodes: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738b0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features shape: torch.Size([13513, 5])\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Item Feature Tensor\n",
    "item_features_df = filtered_meta_df.copy()\n",
    "item_features_df['item_idx'] = item_enc.transform(item_features_df['parent_asin'])\n",
    "\n",
    "num_cols = [\n",
    "    'average_rating',\n",
    "    'rating_number',\n",
    "    'price',\n",
    "    'n_features',\n",
    "    'n_description_items'\n",
    "]\n",
    "\n",
    "item_feat_mat = (\n",
    "    item_features_df\n",
    "    .set_index('item_idx')[num_cols]\n",
    "    .astype(float)\n",
    "    .sort_index()\n",
    "    .values\n",
    ")\n",
    "\n",
    "item_features_tensor = torch.from_numpy(item_feat_mat).float()\n",
    "print(\"Item features shape:\", item_features_tensor.shape)  # [num_items, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56fc97ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User features shape: torch.Size([742651, 3])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: User Feature Tensor\n",
    "user_stats = (\n",
    "    filtered_reviews_df\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        avg_rating_given=('rating','mean'),\n",
    "        review_count=('rating','count'),\n",
    "        mean_recency_weight=('recency_weight','mean')\n",
    "    )\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "user_features_df = (\n",
    "    user_stats\n",
    "    .reindex(user_enc.classes_)\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "user_feat_mat = user_features_df.values.astype(float)\n",
    "user_features_tensor = torch.from_numpy(user_feat_mat).float()\n",
    "print(\"User features shape:\", user_features_tensor.shape)  # [num_users, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b0e5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined node feature matrix shape: torch.Size([756164, 5])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Align Feature Dimensions and Combine\n",
    "# Pad user features with zeros for the two extra dimensions\n",
    "zeros_padding = torch.zeros((num_users, item_features_tensor.size(1) - user_features_tensor.size(1)))\n",
    "user_padded = torch.cat([user_features_tensor, zeros_padding], dim=1)\n",
    "\n",
    "# Combine\n",
    "x = torch.cat([user_padded, item_features_tensor], dim=0)\n",
    "assert x.size(0) == num_nodes\n",
    "print(\"Combined node feature matrix shape:\", x.shape)  # [num_nodes, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dbec7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge index shape: torch.Size([2, 1138185])\n",
      "Edge attr shape: torch.Size([1138185, 2])\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Build edge_index and edge_attr\n",
    "src = torch.tensor(filtered_reviews_df['user_idx'].values, dtype=torch.long)\n",
    "dst = torch.tensor(filtered_reviews_df['item_idx'].values + num_users, dtype=torch.long)\n",
    "edge_index = torch.stack([src, dst], dim=0)\n",
    "\n",
    "edge_attr = torch.tensor(\n",
    "    filtered_reviews_df[['rating','recency_weight']].values.astype(float),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "print(\"Edge index shape:\", edge_index.shape)\n",
    "print(\"Edge attr shape:\", edge_attr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a3a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[756164, 5], edge_index=[2, 1138185], edge_attr=[1138185, 2])\n",
      "tensor([[5.0000e+00, 1.0000e+00, 2.7027e-04, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 2.0000e+00, 3.5907e-04, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 1.0000e+00, 9.0744e-04, 0.0000e+00, 0.0000e+00],\n",
      "        ...,\n",
      "        [4.4000e+00, 8.7000e+01, 3.4900e+02, 5.0000e+00, 0.0000e+00],\n",
      "        [4.7000e+00, 4.9170e+03, 1.1990e+01, 5.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+00, 4.0000e+00, 1.1990e+01, 5.0000e+00, 1.5000e+01]])\n",
      "tensor([[413732, 332183,  67130,  ...,  82190,  82190, 619548],\n",
      "        [750430, 744494, 750817,  ..., 752527, 752934, 754028]])\n",
      "tensor([[5.0000e+00, 3.2862e-04],\n",
      "        [5.0000e+00, 3.0694e-04],\n",
      "        [5.0000e+00, 4.5537e-04],\n",
      "        ...,\n",
      "        [4.0000e+00, 1.5408e-03],\n",
      "        [4.0000e+00, 1.6529e-03],\n",
      "        [5.0000e+00, 1.6529e-03]])\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Pack into PyG Data\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "print(graph)\n",
    "print(graph.x)\n",
    "print(graph.edge_index)\n",
    "print(graph.edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b05579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph saved to 'storex_graph.pt'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(graph, FULL_GRAPH_PATH)\n",
    "print(\"Graph saved to 'storex_graph.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a4fedcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: Data(x=[756164, 5], edge_index=[2, 1934916], edge_attr=[1934916, 2], edge_label=[1934916], edge_label_index=[2, 1934916])\n",
      "Val data: Data(x=[756164, 5], edge_index=[2, 1934916], edge_attr=[1934916, 2], edge_label=[113818], edge_label_index=[2, 113818])\n",
      "Test data: Data(x=[756164, 5], edge_index=[2, 2048734], edge_attr=[2048734, 2], edge_label=[227636], edge_label_index=[2, 227636])\n",
      "Train edges: torch.Size([2, 1934916])\n",
      "Validation edges: torch.Size([2, 1934916])\n",
      "Test edges: torch.Size([2, 2048734])\n",
      "Edge attributes sample: tensor([[5.0000e+00, 3.2862e-04],\n",
      "        [5.0000e+00, 3.0694e-04],\n",
      "        [5.0000e+00, 4.5537e-04],\n",
      "        [5.0000e+00, 4.6490e-04],\n",
      "        [5.0000e+00, 3.7679e-04],\n",
      "        [5.0000e+00, 3.0276e-04],\n",
      "        [5.0000e+00, 3.6232e-04],\n",
      "        [5.0000e+00, 6.8540e-04],\n",
      "        [5.0000e+00, 5.8789e-04],\n",
      "        [5.0000e+00, 8.5543e-04]])\n",
      "Edge attributes distribution: 2.3596959114074707, 2.394904375076294\n",
      "Positive samples: 1934916\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'edge_index_neg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEdge attributes distribution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_attr.mean()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_attr.std()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPositive samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data.edge_index.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNegative samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtrain_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index_neg\u001b[49m.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch_geometric/data/data.py:561\u001b[39m, in \u001b[36mData.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m_store\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object was created by an older version of PyG. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    558\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf this error occurred while loading an already existing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdataset, remove the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprocessed/\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directory in the dataset\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mroot folder and try again.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch_geometric/data/storage.py:96\u001b[39m, in \u001b[36mBaseStorage.__getattr__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'GlobalStorage' object has no attribute 'edge_index_neg'"
     ]
    }
   ],
   "source": [
    "# Applying RandomLinkSplit to split the graph\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# Define the transform\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,         # Amazon graph should be treated as undirected\n",
    "    add_negative_train_samples=True,\n",
    "    edge_types=('edge_index',),  # optional, here for clarity\n",
    "    rev_edge_types=None\n",
    ")\n",
    "\n",
    "# Apply the transform\n",
    "train_data, val_data, test_data = transform(graph)\n",
    "\n",
    "# Print the results\n",
    "print(\"Train data:\", train_data)\n",
    "print(\"Val data:\", val_data)\n",
    "print(\"Test data:\", test_data)\n",
    "\n",
    "# Save the splits\n",
    "torch.save(train_data, TRAIN_GRAPH_PATH)\n",
    "torch.save(val_data, VAL_GRAPH_PATH)\n",
    "torch.save(test_data, TEST_GRAPH_PATH)\n",
    "\n",
    "print(f\"Train edges: {train_data.edge_index.shape}\")\n",
    "print(f\"Validation edges: {val_data.edge_index.shape}\")\n",
    "print(f\"Test edges: {test_data.edge_index.shape}\")\n",
    "\n",
    "print(f\"Edge attributes sample: {edge_attr[:10]}\")\n",
    "print(f\"Edge attributes distribution: {edge_attr.mean()}, {edge_attr.std()}\")\n",
    "\n",
    "print(f\"Positive samples: {train_data.edge_index.shape[1]}\")\n",
    "print(f\"Negative samples: {train_data.edge_index_neg.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49363e8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     plt.show()\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Use on your train_data, val_data, or full graph\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mvisualize_largest_connected_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrain Data - Largest Connected Component\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mvisualize_largest_connected_component\u001b[39m\u001b[34m(edge_index, title)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Draw the subgraph\u001b[39;00m\n\u001b[32m     19\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m pos = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspring_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m nx.draw(G_sub, pos, with_labels=\u001b[38;5;28;01mFalse\u001b[39;00m, node_size=\u001b[32m30\u001b[39m, node_color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m, alpha=\u001b[32m0.6\u001b[39m, edge_color=\u001b[33m\"\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m\"\u001b[39m, width=\u001b[32m0.5\u001b[39m)\n\u001b[32m     22\u001b[39m plt.title(title)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 4:4\u001b[39m, in \u001b[36margmap_spring_layout_1\u001b[39m\u001b[34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/networkx/drawing/layout.py:486\u001b[39m, in \u001b[36mspring_layout\u001b[39m\u001b[34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[39m\n\u001b[32m    484\u001b[39m         nnodes, _ = A.shape\n\u001b[32m    485\u001b[39m         k = dom_size / np.sqrt(nnodes)\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     pos = \u001b[43m_sparse_fruchterman_reingold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    490\u001b[39m     A = nx.to_numpy_array(G, weight=weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 20:4\u001b[39m, in \u001b[36margmap__sparse_fruchterman_reingold_17\u001b[39m\u001b[34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/networkx/drawing/layout.py:623\u001b[39m, in \u001b[36m_sparse_fruchterman_reingold\u001b[39m\u001b[34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[39m\n\u001b[32m    621\u001b[39m distance = np.sqrt((delta**\u001b[32m2\u001b[39m).sum(axis=\u001b[32m0\u001b[39m))\n\u001b[32m    622\u001b[39m \u001b[38;5;66;03m# enforce minimum distance of 0.01\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m distance = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;66;03m# the adjacency matrix row\u001b[39;00m\n\u001b[32m    625\u001b[39m Ai = A.getrowview(i).toarray()  \u001b[38;5;66;03m# TODO: revisit w/ sparse 1D container\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_largest_connected_component(edge_index, title=\"Graph Sample\"):\n",
    "    \"\"\"\n",
    "    Find and visualize the largest connected component in a graph given by edge_index.\n",
    "    \"\"\"\n",
    "    # Convert to NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    edges = edge_index.numpy().T\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Get largest connected component\n",
    "    largest_cc_nodes = max(nx.connected_components(G), key=len)\n",
    "    G_sub = G.subgraph(largest_cc_nodes).copy()\n",
    "\n",
    "    # Draw the subgraph\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(G_sub, seed=42)\n",
    "    nx.draw(G_sub, pos, with_labels=False, node_size=30, node_color=\"blue\", alpha=0.6, edge_color=\"gray\", width=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Use on your train_data, val_data, or full graph\n",
    "visualize_largest_connected_component(train_data.edge_index, title=\"Train Data - Largest Connected Component\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bbb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m test_sample_edge_index = test_data.edge_index[:, torch.randperm(test_data.edge_index.size(\u001b[32m1\u001b[39m))[:\u001b[32m1000\u001b[39m]]  \u001b[38;5;66;03m# Sample 500 edges\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Visualize each sample\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mvisualize_graph_with_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sample_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTrain Data Subsample\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m visualize_graph_with_edges(val_sample_edge_index, title=\u001b[33m\"\u001b[39m\u001b[33mValidation Data Subsample\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m visualize_graph_with_edges(test_sample_edge_index, title=\u001b[33m\"\u001b[39m\u001b[33mTest Data Subsample\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mvisualize_graph_with_edges\u001b[39m\u001b[34m(edge_index, title)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Visualize the graph using networkx\u001b[39;00m\n\u001b[32m     12\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m pos = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspring_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Layout the nodes\u001b[39;00m\n\u001b[32m     14\u001b[39m nx.draw(G, pos, with_labels=\u001b[38;5;28;01mFalse\u001b[39;00m, node_size=\u001b[32m20\u001b[39m, node_color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m, alpha=\u001b[32m0.6\u001b[39m, edge_color=\u001b[33m\"\u001b[39m\u001b[33mgray\u001b[39m\u001b[33m\"\u001b[39m, width=\u001b[32m0.5\u001b[39m)\n\u001b[32m     15\u001b[39m plt.title(title)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 4:4\u001b[39m, in \u001b[36margmap_spring_layout_1\u001b[39m\u001b[34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/networkx/drawing/layout.py:486\u001b[39m, in \u001b[36mspring_layout\u001b[39m\u001b[34m(G, k, pos, fixed, iterations, threshold, weight, scale, center, dim, seed)\u001b[39m\n\u001b[32m    484\u001b[39m         nnodes, _ = A.shape\n\u001b[32m    485\u001b[39m         k = dom_size / np.sqrt(nnodes)\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     pos = \u001b[43m_sparse_fruchterman_reingold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    490\u001b[39m     A = nx.to_numpy_array(G, weight=weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/networkx/utils/decorators.py:788\u001b[39m, in \u001b[36margmap.__call__.<locals>.func\u001b[39m\u001b[34m(_argmap__wrapper, *args, **kwargs)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc\u001b[39m(*args, __wrapper=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43margmap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_lazy_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__wrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 20:4\u001b[39m, in \u001b[36margmap__sparse_fruchterman_reingold_17\u001b[39m\u001b[34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/networkx/drawing/layout.py:621\u001b[39m, in \u001b[36m_sparse_fruchterman_reingold\u001b[39m\u001b[34m(A, k, pos, fixed, iterations, threshold, dim, seed)\u001b[39m\n\u001b[32m    619\u001b[39m delta = (pos[i] - pos).T\n\u001b[32m    620\u001b[39m \u001b[38;5;66;03m# distance between points\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m distance = np.sqrt(\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    622\u001b[39m \u001b[38;5;66;03m# enforce minimum distance of 0.01\u001b[39;00m\n\u001b[32m    623\u001b[39m distance = np.where(distance < \u001b[32m0.01\u001b[39m, \u001b[32m0.01\u001b[39m, distance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/numpy/_core/_methods.py:52\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     51\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_graph_with_edges(edge_index, title=\"Graph\"):\n",
    "    # Convert edge_index to a networkx graph\n",
    "    G = nx.Graph()\n",
    "    edges = edge_index.numpy().T\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Visualize the graph using networkx\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos = nx.spring_layout(G, seed=42)  # Layout the nodes\n",
    "    nx.draw(G, pos, with_labels=False, node_size=20, node_color=\"blue\", alpha=0.6, edge_color=\"gray\", width=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Randomly sample a subset of the edge_index from train, val, and test data\n",
    "train_sample_edge_index = train_data.edge_index[:, torch.randperm(train_data.edge_index.size(1))[:10000]]  # Sample 500 edges\n",
    "val_sample_edge_index = val_data.edge_index[:, torch.randperm(val_data.edge_index.size(1))[:1000]]  # Sample 500 edges\n",
    "test_sample_edge_index = test_data.edge_index[:, torch.randperm(test_data.edge_index.size(1))[:1000]]  # Sample 500 edges\n",
    "\n",
    "# Visualize each sample\n",
    "visualize_graph_with_edges(train_sample_edge_index, title=\"Train Data Subsample\")\n",
    "visualize_graph_with_edges(val_sample_edge_index, title=\"Validation Data Subsample\")\n",
    "visualize_graph_with_edges(test_sample_edge_index, title=\"Test Data Subsample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb2f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
