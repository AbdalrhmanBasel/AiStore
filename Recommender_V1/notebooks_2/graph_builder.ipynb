{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "529ebe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e686aa",
   "metadata": {},
   "source": [
    "# 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c76dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from srcs.utils.logger import get_module_logger\n",
    "from srcs.utils.settings import (\n",
    "    CLEANED_REVIEWS_PATH_CSV,\n",
    "    CLEANED_METADATA_PATH_CSV,\n",
    "    FULL_GRAPH_PATH,\n",
    "    TRAIN_GRAPH_PATH,\n",
    "    VAL_GRAPH_PATH,\n",
    "    TEST_GRAPH_PATH,\n",
    "    IMAGES_DIR,\n",
    "    GNN_MODEL_SAVE_PATH,\n",
    "    PREDICTOR_MODEL_SAVE_PATH\n",
    ")\n",
    "\n",
    "# Configure paths\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir, os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_module_logger(\"graph_builder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed120a",
   "metadata": {},
   "source": [
    "# 2. Data Loading with Metadata Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e90fb3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 17:49:11] [INFO] graph_builder: Sampled 10,000 reviews\n",
      "[2025-05-08 17:49:12] [INFO] graph_builder: Filtered metadata to 638 items from 638\n",
      "[2025-05-08 17:49:12] [INFO] graph_builder: Unique items in sampled reviews: 8,354\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the full dataset\n",
    "reviews_df = pd.read_csv(CLEANED_REVIEWS_PATH_CSV)\n",
    "meta_df = pd.read_csv(CLEANED_METADATA_PATH_CSV)\n",
    "\n",
    "# Randomly sample 50,000 reviews\n",
    "reviews_df = reviews_df.sample(n=10_000, random_state=42)\n",
    "\n",
    "# Filter metadata to only include items in sampled reviews\n",
    "filtered_item_ids = reviews_df['parent_asin'].unique()\n",
    "meta_df = meta_df[meta_df['parent_asin'].isin(filtered_item_ids)]\n",
    "\n",
    "# Logging\n",
    "logger.info(f\"Sampled {len(reviews_df):,} reviews\")\n",
    "logger.info(f\"Filtered metadata to {len(meta_df):,} items from {len(meta_df):,}\")\n",
    "logger.info(f\"Unique items in sampled reviews: {len(filtered_item_ids):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9de35d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>recency</th>\n",
       "      <th>recency_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13162781</th>\n",
       "      <td>AFCO6LEANZBTDWKI4BH6BO7H4PIA</td>\n",
       "      <td>B0BKQWX8ZJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019-06-26 17:12:09.179</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>2137</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232846</th>\n",
       "      <td>AH3L645CVARFM3WRPSP3G26WOAEA</td>\n",
       "      <td>B005BH3QOY</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2014-06-17 21:14:07.000</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>3971</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284619</th>\n",
       "      <td>AHIAQCSWKTDLBS4AV7TZMMHD5J2Q</td>\n",
       "      <td>B01M4NU4OM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-03-19 17:34:21.529</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>2601</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6794797</th>\n",
       "      <td>AH7VRATJ52IOBIL3HQPYFKYLHWIQ</td>\n",
       "      <td>B0BYYJPGQB</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-06-29 13:18:45.132</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>2499</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364485</th>\n",
       "      <td>AFUZ3QNYGXTLGGWTUTXD6PY4GLQA</td>\n",
       "      <td>B00AJFTHX2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-05-16 12:27:58.000</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>3273</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user_id parent_asin  rating  \\\n",
       "13162781  AFCO6LEANZBTDWKI4BH6BO7H4PIA  B0BKQWX8ZJ     5.0   \n",
       "2232846   AH3L645CVARFM3WRPSP3G26WOAEA  B005BH3QOY     4.0   \n",
       "8284619   AHIAQCSWKTDLBS4AV7TZMMHD5J2Q  B01M4NU4OM     5.0   \n",
       "6794797   AH7VRATJ52IOBIL3HQPYFKYLHWIQ  B0BYYJPGQB     5.0   \n",
       "5364485   AFUZ3QNYGXTLGGWTUTXD6PY4GLQA  B00AJFTHX2     5.0   \n",
       "\n",
       "                        timestamp  year  month  day  hour  minute  recency  \\\n",
       "13162781  2019-06-26 17:12:09.179  2019      6   26    17      12     2137   \n",
       "2232846   2014-06-17 21:14:07.000  2014      6   17    21      14     3971   \n",
       "8284619   2018-03-19 17:34:21.529  2018      3   19    17      34     2601   \n",
       "6794797   2018-06-29 13:18:45.132  2018      6   29    13      18     2499   \n",
       "5364485   2016-05-16 12:27:58.000  2016      5   16    12      27     3273   \n",
       "\n",
       "          recency_weight  \n",
       "13162781        0.000468  \n",
       "2232846         0.000252  \n",
       "8284619         0.000384  \n",
       "6794797         0.000400  \n",
       "5364485         0.000305  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88f0a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>price</th>\n",
       "      <th>store</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_description_items</th>\n",
       "      <th>first_image</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>date_first_available</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Computers</td>\n",
       "      <td>KHOMO - iPad 2 3 and 4 Generation Case - DUAL ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2745</td>\n",
       "      <td>11.95</td>\n",
       "      <td>Khomo</td>\n",
       "      <td>B06XKRXLDR</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31+mP+y8Uo...</td>\n",
       "      <td>Khomo</td>\n",
       "      <td>Black</td>\n",
       "      <td>2011-05-13</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>All Electronics</td>\n",
       "      <td>Charger for MacBook Pro 10FT, 96W USB C Charge...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2141</td>\n",
       "      <td>35.99</td>\n",
       "      <td>Ifeart</td>\n",
       "      <td>B07WZT643Q</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/21QlbdFXAG...</td>\n",
       "      <td>Ifeart</td>\n",
       "      <td>White</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "      <td>C&amp;E High Speed HDMI Cable with Ethernet Black,...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>531</td>\n",
       "      <td>8.99</td>\n",
       "      <td>C&amp;E</td>\n",
       "      <td>B07Q1JN792</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41IfnleVoM...</td>\n",
       "      <td>C&amp;E</td>\n",
       "      <td>1 Pack</td>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Computers</td>\n",
       "      <td>Laptop Sleeve Elastic Neoprene Case Compatible...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8298</td>\n",
       "      <td>15.99</td>\n",
       "      <td>Hseok</td>\n",
       "      <td>B071YJFTV4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51wJ5C7w1+...</td>\n",
       "      <td>Hseok</td>\n",
       "      <td>Butterfly</td>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Computers</td>\n",
       "      <td>ProCase 14-15.6 Inch Laptop Bag Messenger Shou...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1015</td>\n",
       "      <td>25.99</td>\n",
       "      <td>Procase</td>\n",
       "      <td>B07CRQDTKM</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/510HCN8zHb...</td>\n",
       "      <td>Procase</td>\n",
       "      <td>Grey</td>\n",
       "      <td>2016-09-22</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           main_category                                              title  \\\n",
       "21             Computers  KHOMO - iPad 2 3 and 4 Generation Case - DUAL ...   \n",
       "35       All Electronics  Charger for MacBook Pro 10FT, 96W USB C Charge...   \n",
       "66  Home Audio & Theater  C&E High Speed HDMI Cable with Ethernet Black,...   \n",
       "73             Computers  Laptop Sleeve Elastic Neoprene Case Compatible...   \n",
       "83             Computers  ProCase 14-15.6 Inch Laptop Bag Messenger Shou...   \n",
       "\n",
       "    average_rating  rating_number  price    store parent_asin  n_features  \\\n",
       "21             4.5           2745  11.95    Khomo  B06XKRXLDR           5   \n",
       "35             4.5           2141  35.99   Ifeart  B07WZT643Q           5   \n",
       "66             4.6            531   8.99      C&E  B07Q1JN792           5   \n",
       "73             4.6           8298  15.99    Hseok  B071YJFTV4           5   \n",
       "83             4.6           1015  25.99  Procase  B07CRQDTKM           5   \n",
       "\n",
       "    n_description_items                                        first_image  \\\n",
       "21                    1  https://m.media-amazon.com/images/I/31+mP+y8Uo...   \n",
       "35                    0  https://m.media-amazon.com/images/I/21QlbdFXAG...   \n",
       "66                   16  https://m.media-amazon.com/images/I/41IfnleVoM...   \n",
       "73                    0  https://m.media-amazon.com/images/I/51wJ5C7w1+...   \n",
       "83                    0  https://m.media-amazon.com/images/I/510HCN8zHb...   \n",
       "\n",
       "      brand      color date_first_available primary_category rating_bin  \n",
       "21    Khomo      Black           2011-05-13      Electronics     Medium  \n",
       "35   Ifeart      White           2019-09-23      Electronics     Medium  \n",
       "66      C&E     1 Pack           2015-01-21      Electronics       High  \n",
       "73    Hseok  Butterfly           2020-07-10      Electronics       High  \n",
       "83  Procase       Grey           2016-09-22      Electronics       High  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9247dc",
   "metadata": {},
   "source": [
    "# 3. Bipartite Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c51b76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: HeteroData(\n",
      "  user={ x=[9945, 64] },\n",
      "  item={ x=[8354, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[10000, 2],\n",
      "    edge_weight=[10000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[10000, 2],\n",
      "    edge_weight=[10000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Encode users and items into index form\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# Assuming reviews_df is already loaded\n",
    "reviews_df['user_idx'] = user_encoder.fit_transform(reviews_df['user_id'])\n",
    "reviews_df['item_idx'] = item_encoder.fit_transform(reviews_df['parent_asin'])\n",
    "\n",
    "# Save mappings (optional but helpful later)\n",
    "user_id_map = dict(zip(reviews_df['user_id'], reviews_df['user_idx']))\n",
    "item_id_map = dict(zip(reviews_df['parent_asin'], reviews_df['item_idx']))\n",
    "\n",
    "# 2. Build edge_index efficiently by stacking user_idx and item_idx\n",
    "edge_index = torch.tensor(\n",
    "    np.column_stack([reviews_df['user_idx'].values, reviews_df['item_idx'].values]), \n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "# 3. Extract ratings as edge weights\n",
    "ratings = torch.tensor(reviews_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# 4. Build HeteroData\n",
    "data = HeteroData()\n",
    "\n",
    "# Assuming user_feats and item_feats are available or generated, you can replace these with actual features\n",
    "data['user'].x = torch.randn(reviews_df['user_idx'].nunique(), 64)  # Random user features (64-dimensional)\n",
    "data['item'].x = torch.randn(reviews_df['item_idx'].nunique(), 64)  # Random item features (64-dimensional)\n",
    "\n",
    "# Adding edges with weights\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['user', 'rates', 'item'].edge_weight = ratings\n",
    "\n",
    "# Optional: Reverse edges for item -> user (not mandatory but useful for reverse propagation if needed)\n",
    "data['item', 'rev_rates', 'user'].edge_index = edge_index.flip(0)  # If you need the reverse edges\n",
    "data['item', 'rev_rates', 'user'].edge_weight = ratings  # Same ratings can be used for the reverse edges\n",
    "\n",
    "print(f\"Graph: {data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981b8f3",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering with Cold-Start Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7feed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: HeteroData(\n",
      "  user={ x=[9945, 64] },\n",
      "  item={ x=[8354, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[2, 10000],\n",
      "    edge_weight=[10000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[2, 10000],\n",
      "    edge_weight=[10000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Encode users and items into index form\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# Assuming reviews_df is already loaded\n",
    "reviews_df['user_idx'] = user_encoder.fit_transform(reviews_df['user_id'])\n",
    "reviews_df['item_idx'] = item_encoder.fit_transform(reviews_df['parent_asin'])\n",
    "\n",
    "# Save mappings (optional but helpful later)\n",
    "user_id_map = dict(zip(reviews_df['user_id'], reviews_df['user_idx']))\n",
    "item_id_map = dict(zip(reviews_df['parent_asin'], reviews_df['item_idx']))\n",
    "\n",
    "# 2. Build edge_index\n",
    "edge_index = torch.tensor([\n",
    "    reviews_df['user_idx'].values,\n",
    "    reviews_df['item_idx'].values\n",
    "], dtype=torch.long)\n",
    "\n",
    "# 3. Extract ratings as edge weights\n",
    "ratings = torch.tensor(reviews_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# 4. Build HeteroData\n",
    "data = HeteroData()\n",
    "\n",
    "# Assuming user_feats and item_feats are available or generated, you can replace these with actual features\n",
    "data['user'].x = torch.randn(reviews_df['user_idx'].nunique(), 64)  # Random user features (64-dimensional)\n",
    "data['item'].x = torch.randn(reviews_df['item_idx'].nunique(), 64)  # Random item features (64-dimensional)\n",
    "\n",
    "# Adding edges with weights\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['user', 'rates', 'item'].edge_weight = ratings\n",
    "\n",
    "# Optional: Reverse edges for item -> user (not mandatory but useful for reverse propagation if needed)\n",
    "data['item', 'rev_rates', 'user'].edge_index = edge_index.flip(0)  # If you need the reverse edges\n",
    "data['item', 'rev_rates', 'user'].edge_weight = ratings  # Same ratings can be used for the reverse edges\n",
    "\n",
    "print(f\"Graph: {data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4424b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-08 17:49:12] [INFO] graph_builder: Saved full graph to /home/abdalrhman/Desktop/Graduation Project/AiStore/Recommender_V1/data/processed/graph_splits/full_graph.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs split and saved: train → /home/abdalrhman/Desktop/Graduation Project/AiStore/Recommender_V1/data/processed/graph_splits/graph_train.pt, val → /home/abdalrhman/Desktop/Graduation Project/AiStore/Recommender_V1/data/processed/graph_splits/graph_val.pt, test → /home/abdalrhman/Desktop/Graduation Project/AiStore/Recommender_V1/data/processed/graph_splits/graph_test.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# 1. Apply the split (automatically adds reverse edge)\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,  # 10% of edges for validation\n",
    "    num_test=0.1,  # 10% of edges for testing\n",
    "    is_undirected=True,  # Treat edges as undirected for link prediction\n",
    "    add_negative_train_samples=True,  # Automatically generate negative samples for training\n",
    "    edge_types=('user', 'rates', 'item'),  # Specify the edge type (user -> item)\n",
    "    rev_edge_types=('item', 'rev_rates', 'user')  # Reverse edge type for item -> user\n",
    ")\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "torch.save(train_data, TRAIN_GRAPH_PATH)\n",
    "torch.save(val_data, VAL_GRAPH_PATH)\n",
    "torch.save(test_data, TEST_GRAPH_PATH)\n",
    "torch.save(data, FULL_GRAPH_PATH)\n",
    "\n",
    "logger.info(f\"Saved full graph to {FULL_GRAPH_PATH}\")\n",
    "\n",
    "# Logging the splits\n",
    "print(f\"Graphs split and saved: train → {TRAIN_GRAPH_PATH}, val → {VAL_GRAPH_PATH}, test → {TEST_GRAPH_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "944a4c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[9945, 64] },\n",
      "  item={ x=[8354, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[2, 8000],\n",
      "    edge_weight=[8000],\n",
      "    edge_label=[16000],\n",
      "    edge_label_index=[2, 16000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[2, 8000],\n",
      "    edge_weight=[8000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(train_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0f85120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[9945, 64] },\n",
      "  item={ x=[8354, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[2, 8000],\n",
      "    edge_weight=[8000],\n",
      "    edge_label=[2000],\n",
      "    edge_label_index=[2, 2000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[2, 8000],\n",
      "    edge_weight=[8000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c2ef4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[9945, 64] },\n",
      "  item={ x=[8354, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[2, 9000],\n",
      "    edge_weight=[9000],\n",
      "    edge_label=[2000],\n",
      "    edge_label_index=[2, 2000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[2, 9000],\n",
      "    edge_weight=[9000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e51a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ x=[9945, 64] },\n",
      "  item={ x=[8354, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[2, 10000],\n",
      "    edge_weight=[10000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[2, 10000],\n",
      "    edge_weight=[10000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bdf474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "# Load the full graph\n",
    "# full_data = torch.load(FULL_GRAPH_PATH)\n",
    "\n",
    "# Load train, validation, and test splits\n",
    "train_data = torch.load(TRAIN_GRAPH_PATH, weights_only=False)\n",
    "val_data = torch.load(VAL_GRAPH_PATH, weights_only=False)\n",
    "test_data = torch.load(TEST_GRAPH_PATH, weights_only=False)\n",
    "\n",
    "# Optional: Move data to device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# full_data = full_data.to(device)\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17099fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b251ea92",
   "metadata": {},
   "source": [
    "# 5. Graph Splitting with Bipartite Awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630eca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9308cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, Linear\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ─── 1) Data Preparation ───────────────────────────────────────────────\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=[('user', 'rates', 'item')],\n",
    "    rev_edge_types=[('item', 'rev_rates', 'user')]\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "train_data, val_data, test_data = [d.to(device) for d in (train_data, val_data, test_data)]\n",
    "\n",
    "num_items = train_data['item'].x.size(0)\n",
    "edge_set = set(map(tuple, train_data['user','rates','item'].edge_index.cpu().t().tolist()))\n",
    "\n",
    "# ─── 2) Fixed Heterogeneous GraphSAGE Model ────────────────────────────\n",
    "class HeteroGraphSAGE(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'rates', 'item'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('item', 'rev_rates', 'user'): SAGEConv((-1, -1), hidden_dim)\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'rates', 'item'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('item', 'rev_rates', 'user'): SAGEConv(hidden_dim, hidden_dim)\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        # BatchNorm for each node type\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # Dropout (now applied per node type)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # First conv layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.bn1(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: self.dropout(x) for key, x in x_dict.items()}  # ✅ Fixed: Apply dropout per tensor\n",
    "\n",
    "        # Second conv layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.bn2(x) for key, x in x_dict.items()}\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "# ─── 3) Link Predictor with MLP ───────────────────────────────────────\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, src, dst):\n",
    "        return self.mlp(torch.cat([src, dst], dim=-1)).squeeze()\n",
    "\n",
    "# ─── 4) Initialize Model, Optimizer, Scheduler ───────────────────────\n",
    "hidden_dim = 128\n",
    "gnn = HeteroGraphSAGE(hidden_dim).to(device)\n",
    "predictor = LinkPredictor(hidden_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': gnn.parameters(), 'lr': 1e-3},\n",
    "    {'params': predictor.parameters(), 'lr': 5e-4}\n",
    "], weight_decay=1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a74c2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5) Training with Hard Negative Sampling ─────────────────────────\n",
    "def train_epoch(data, neg_ratio=5):\n",
    "    gnn.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    emb = gnn(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    edge_index = data['user', 'rates', 'item'].edge_index\n",
    "    src, dst = edge_index[0], edge_index[1]\n",
    "    pos_pred = predictor(emb['user'][src], emb['item'][dst])\n",
    "\n",
    "    # Hard negative sampling\n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in src.unique().cpu().tolist():\n",
    "        seen = dst[src == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*neg_ratio,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "\n",
    "    if not neg_src:\n",
    "        return 0.0\n",
    "\n",
    "    neg_src = torch.cat(neg_src)\n",
    "    neg_dst = torch.cat(neg_dst)\n",
    "\n",
    "    neg_pred = predictor(emb['user'][neg_src], emb['item'][neg_dst])\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(\n",
    "        torch.cat([pos_pred, neg_pred]),\n",
    "        torch.cat([torch.ones_like(pos_pred), torch.zeros_like(neg_pred)])\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# ─── 6) Evaluation with Dynamic Threshold ───────────────────────────\n",
    "@torch.no_grad()\n",
    "def evaluate(data):\n",
    "    gnn.eval()\n",
    "    predictor.eval()\n",
    "    emb = gnn(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    edge_index = data['user', 'rates', 'item'].edge_index\n",
    "    src, dst = edge_index[0], edge_index[1]\n",
    "    \n",
    "    pos_pred = predictor(emb['user'][src], emb['item'][dst]).cpu().numpy()\n",
    "    pos_labels = np.ones(len(pos_pred))\n",
    "\n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in src.unique().cpu().tolist():\n",
    "        seen = dst[src == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*5,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "\n",
    "    if not neg_src:\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    neg_pred = predictor(emb['user'][torch.cat(neg_src)], emb['item'][torch.cat(neg_dst)]).cpu().numpy()\n",
    "    neg_labels = np.zeros(len(neg_pred))\n",
    "\n",
    "    scores = np.concatenate([pos_pred, neg_pred])\n",
    "    labels = np.concatenate([pos_labels, neg_labels])\n",
    "\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    prec, rec, threshs = precision_recall_curve(labels, scores)\n",
    "    f1s = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
    "    best_idx = np.argmax(f1s)\n",
    "    best_thresh = threshs[best_idx]\n",
    "\n",
    "    preds = (scores >= best_thresh).astype(int)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    prec_final = precision_score(labels, preds)\n",
    "    rec_final = recall_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'f1': f1,\n",
    "        'precision': prec_final,\n",
    "        'recall': rec_final,\n",
    "        'threshold': best_thresh\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c4f4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ─── 7) Training Loop with Early Stopping ───────────────────────────\n",
    "# best_f1 = 0.0\n",
    "# patience = 0\n",
    "\n",
    "# for epoch in range(1, 100):\n",
    "#     loss = train_epoch(train_data)\n",
    "#     val_metrics = evaluate(val_data)\n",
    "#     scheduler.step(val_metrics['f1'])\n",
    "\n",
    "#     print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | \"\n",
    "#           f\"Val AUC: {val_metrics['auc']:.4f} | F1: {val_metrics['f1']:.4f} | \"\n",
    "#           f\"Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f}\")\n",
    "\n",
    "#     if val_metrics['f1'] > best_f1:\n",
    "#         best_f1 = val_metrics['f1']\n",
    "#         torch.save(gnn.state_dict(), 'best_gnn.pth')\n",
    "#         torch.save(predictor.state_dict(), 'best_predictor.pth')\n",
    "#         patience = 0\n",
    "#     else:\n",
    "#         patience += 1\n",
    "#         if patience >= 20:\n",
    "#             print(\"Early stopping triggered.\")\n",
    "#             break\n",
    "\n",
    "# # ─── 8) Final Test Evaluation ───────────────────────────────────────\n",
    "# gnn.load_state_dict(torch.load('best_gnn.pth'))\n",
    "# predictor.load_state_dict(torch.load('best_predictor.pth'))\n",
    "# test_metrics = evaluate(test_data)\n",
    "\n",
    "# print(\"\\nTest Metrics:\")\n",
    "# print(f\"AUC: {test_metrics['auc']:.4f} | Precision: {test_metrics['precision']:.4f}\")\n",
    "# print(f\"Recall: {test_metrics['recall']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "# print(f\"Optimal Threshold: {test_metrics['threshold']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5b0edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the best model after training\n",
    "# torch.save(gnn.state_dict(), GNN_MODEL_SAVE_PATH)\n",
    "# torch.save(predictor.state_dict(), PREDICTOR_MODEL_SAVE_PATH)\n",
    "\n",
    "# print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fc4376c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkPredictor(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(256, 128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(128, 1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate model architecture\n",
    "hidden_dim = 128\n",
    "gnn = HeteroGraphSAGE(hidden_dim)\n",
    "predictor = LinkPredictor(hidden_dim)\n",
    "\n",
    "# Load saved weights with map_location set to 'cpu'\n",
    "gnn.load_state_dict(torch.load(GNN_MODEL_SAVE_PATH, map_location=torch.device('cpu')))\n",
    "predictor.load_state_dict(torch.load(PREDICTOR_MODEL_SAVE_PATH, map_location=torch.device('cpu')))\n",
    "\n",
    "# Move models to desired device (optional)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gnn = gnn.to(device)\n",
    "predictor = predictor.to(device)\n",
    "\n",
    "# Set models to evaluation mode for inference\n",
    "gnn.eval()\n",
    "predictor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "26ccf0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkPredictor(\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(256, 128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(128, 1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn.train()\n",
    "predictor.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee341e",
   "metadata": {},
   "source": [
    "# ✅ 1. Top-K Recommendations for a User\n",
    "\n",
    "Recommend top k items for a given user based on predicted interaction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3415a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def recommend(user_id, gnn_model, predictor_model, data, k=10):\n",
    "    \"\"\"\n",
    "    Recommend top-k items for a given user based on learned embeddings.\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): ID of the user\n",
    "        gnn_model: Trained heterogeneous GNN model (HeteroGraphSAGE)\n",
    "        predictor_model: Link predictor (MLP)\n",
    "        data: HeteroData object (val or test split)\n",
    "        k (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "        list: Top-k item IDs recommended for the user\n",
    "    \"\"\"\n",
    "    gnn_model.eval()\n",
    "    predictor_model.eval()\n",
    "\n",
    "    # Get embeddings for all nodes\n",
    "    emb = gnn_model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    # Get user embedding\n",
    "    user_emb = emb['user'][user_id].unsqueeze(0)  # shape: [1, hidden_dim]\n",
    "\n",
    "    # Get all item embeddings\n",
    "    item_embs = emb['item']  # shape: [num_items, hidden_dim]\n",
    "\n",
    "    # Repeat user embedding to match item_embs size\n",
    "    user_embs = user_emb.expand(item_embs.size(0), -1)\n",
    "\n",
    "    # Predict scores for all items\n",
    "    scores = predictor_model(user_embs, item_embs).cpu().numpy()\n",
    "\n",
    "    # Exclude already interacted items\n",
    "    interacted_items = data['user', 'rates', 'item'].edge_index[1][\n",
    "        data['user', 'rates', 'item'].edge_index[0] == user_id\n",
    "    ].cpu().numpy()\n",
    "\n",
    "    # Mask out interacted items\n",
    "    scores[interacted_items] = -np.inf\n",
    "\n",
    "    # Get top-k item indices\n",
    "    top_k_item_ids = np.argpartition(scores, -k)[-k:]\n",
    "    top_k_item_ids = top_k_item_ids[np.argsort(-scores[top_k_item_ids])]  # Sort descending\n",
    "\n",
    "    return top_k_item_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4afe073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Recommended Items for User 0: [4980, 2416, 2674, 7208, 2938]\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "recommended_items = recommend(user_id, gnn, predictor, test_data, k=5)\n",
    "print(f\"Top-5 Recommended Items for User {user_id}: {recommended_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41eaa6",
   "metadata": {},
   "source": [
    "# 2. Item-to-Item Recommendations (Similar Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f43c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def similar_items(item_id, gnn_model, data, k=5):\n",
    "    gnn_model.eval()\n",
    "    emb = gnn_model(data.x_dict, data.edge_index_dict)['item']\n",
    "    item_emb = emb[item_id].unsqueeze(0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    sim = F.cosine_similarity(item_emb, emb).cpu().numpy()\n",
    "    sim[item_id] = -np.inf  # Exclude self\n",
    "    \n",
    "    # Top-k most similar items\n",
    "    top_k = np.argpartition(sim, -k)[-k:]\n",
    "    return top_k[np.argsort(-sim[top_k])].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02daae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4385, 2830, 6862, 3492, 1080]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_items(42, gnn, test_data, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
