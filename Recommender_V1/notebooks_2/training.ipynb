{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529ebe2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore/Recommender_V1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e686aa",
   "metadata": {},
   "source": [
    "# 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c76dbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from srcs.utils.logger import get_module_logger\n",
    "from srcs.utils.settings import (\n",
    "    CLEANED_REVIEWS_PATH_CSV,\n",
    "    CLEANED_METADATA_PATH_CSV,\n",
    "    FULL_GRAPH_PATH,\n",
    "    TRAIN_GRAPH_PATH,\n",
    "    VAL_GRAPH_PATH,\n",
    "    TEST_GRAPH_PATH,\n",
    "    IMAGES_DIR,\n",
    "    GNN_MODEL_SAVE_PATH,\n",
    "    PREDICTOR_MODEL_SAVE_PATH\n",
    ")\n",
    "\n",
    "# Configure paths\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir, os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Initialize logger\n",
    "logger = get_module_logger(\"graph_builder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bdf474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "# Load the full graph\n",
    "# full_data = torch.load(FULL_GRAPH_PATH)\n",
    "\n",
    "# Load train, validation, and test splits\n",
    "train_data = torch.load(TRAIN_GRAPH_PATH, weights_only=False)\n",
    "val_data = torch.load(VAL_GRAPH_PATH, weights_only=False)\n",
    "test_data = torch.load(TEST_GRAPH_PATH, weights_only=False)\n",
    "\n",
    "# Optional: Move data to device (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# full_data = full_data.to(device)\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9308cf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ─── 1) Data Preparation ───────────────────────────────────────────────\u001b[39;00m\n\u001b[32m     13\u001b[39m transform = RandomLinkSplit(\n\u001b[32m     14\u001b[39m     num_val=\u001b[32m0.1\u001b[39m,\n\u001b[32m     15\u001b[39m     num_test=\u001b[32m0.1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     rev_edge_types=[(\u001b[33m'\u001b[39m\u001b[33mitem\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrev_rates\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m train_data, val_data, test_data = transform(\u001b[43mdata\u001b[49m)\n\u001b[32m     23\u001b[39m train_data, val_data, test_data = [d.to(device) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m (train_data, val_data, test_data)]\n\u001b[32m     25\u001b[39m num_items = train_data[\u001b[33m'\u001b[39m\u001b[33mitem\u001b[39m\u001b[33m'\u001b[39m].x.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, Linear\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# ─── 1) Data Preparation ───────────────────────────────────────────────\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=[('user', 'rates', 'item')],\n",
    "    rev_edge_types=[('item', 'rev_rates', 'user')]\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "train_data, val_data, test_data = [d.to(device) for d in (train_data, val_data, test_data)]\n",
    "\n",
    "num_items = train_data['item'].x.size(0)\n",
    "edge_set = set(map(tuple, train_data['user','rates','item'].edge_index.cpu().t().tolist()))\n",
    "\n",
    "# ─── 2) Fixed Heterogeneous GraphSAGE Model ────────────────────────────\n",
    "class HeteroGraphSAGE(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'rates', 'item'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('item', 'rev_rates', 'user'): SAGEConv((-1, -1), hidden_dim)\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'rates', 'item'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('item', 'rev_rates', 'user'): SAGEConv(hidden_dim, hidden_dim)\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        # BatchNorm for each node type\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # Dropout (now applied per node type)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # First conv layer\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.bn1(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: self.dropout(x) for key, x in x_dict.items()}  # ✅ Fixed: Apply dropout per tensor\n",
    "\n",
    "        # Second conv layer\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.bn2(x) for key, x in x_dict.items()}\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "# ─── 3) Link Predictor with MLP ───────────────────────────────────────\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, src, dst):\n",
    "        return self.mlp(torch.cat([src, dst], dim=-1)).squeeze()\n",
    "\n",
    "# ─── 4) Initialize Model, Optimizer, Scheduler ───────────────────────\n",
    "hidden_dim = 128\n",
    "gnn = HeteroGraphSAGE(hidden_dim).to(device)\n",
    "predictor = LinkPredictor(hidden_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': gnn.parameters(), 'lr': 1e-3},\n",
    "    {'params': predictor.parameters(), 'lr': 5e-4}\n",
    "], weight_decay=1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5) Training with Hard Negative Sampling ─────────────────────────\n",
    "def train_epoch(data, neg_ratio=5):\n",
    "    gnn.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    emb = gnn(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    edge_index = data['user', 'rates', 'item'].edge_index\n",
    "    src, dst = edge_index[0], edge_index[1]\n",
    "    pos_pred = predictor(emb['user'][src], emb['item'][dst])\n",
    "\n",
    "    # Hard negative sampling\n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in src.unique().cpu().tolist():\n",
    "        seen = dst[src == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*neg_ratio,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "\n",
    "    if not neg_src:\n",
    "        return 0.0\n",
    "\n",
    "    neg_src = torch.cat(neg_src)\n",
    "    neg_dst = torch.cat(neg_dst)\n",
    "\n",
    "    neg_pred = predictor(emb['user'][neg_src], emb['item'][neg_dst])\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(\n",
    "        torch.cat([pos_pred, neg_pred]),\n",
    "        torch.cat([torch.ones_like(pos_pred), torch.zeros_like(neg_pred)])\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# ─── 6) Evaluation with Dynamic Threshold ───────────────────────────\n",
    "@torch.no_grad()\n",
    "def evaluate(data):\n",
    "    gnn.eval()\n",
    "    predictor.eval()\n",
    "    emb = gnn(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    edge_index = data['user', 'rates', 'item'].edge_index\n",
    "    src, dst = edge_index[0], edge_index[1]\n",
    "    \n",
    "    pos_pred = predictor(emb['user'][src], emb['item'][dst]).cpu().numpy()\n",
    "    pos_labels = np.ones(len(pos_pred))\n",
    "\n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in src.unique().cpu().tolist():\n",
    "        seen = dst[src == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*5,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "\n",
    "    if not neg_src:\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    neg_pred = predictor(emb['user'][torch.cat(neg_src)], emb['item'][torch.cat(neg_dst)]).cpu().numpy()\n",
    "    neg_labels = np.zeros(len(neg_pred))\n",
    "\n",
    "    scores = np.concatenate([pos_pred, neg_pred])\n",
    "    labels = np.concatenate([pos_labels, neg_labels])\n",
    "\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    prec, rec, threshs = precision_recall_curve(labels, scores)\n",
    "    f1s = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
    "    best_idx = np.argmax(f1s)\n",
    "    best_thresh = threshs[best_idx]\n",
    "\n",
    "    preds = (scores >= best_thresh).astype(int)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    prec_final = precision_score(labels, preds)\n",
    "    rec_final = recall_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'f1': f1,\n",
    "        'precision': prec_final,\n",
    "        'recall': rec_final,\n",
    "        'threshold': best_thresh\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 7) Training Loop with Early Stopping ───────────────────────────\n",
    "best_f1 = 0.0\n",
    "patience = 0\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    loss = train_epoch(train_data)\n",
    "    val_metrics = evaluate(val_data)\n",
    "    scheduler.step(val_metrics['f1'])\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | \"\n",
    "          f\"Val AUC: {val_metrics['auc']:.4f} | F1: {val_metrics['f1']:.4f} | \"\n",
    "          f\"Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f}\")\n",
    "\n",
    "    if val_metrics['f1'] > best_f1:\n",
    "        best_f1 = val_metrics['f1']\n",
    "        torch.save(gnn.state_dict(), 'best_gnn.pth')\n",
    "        torch.save(predictor.state_dict(), 'best_predictor.pth')\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 20:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# ─── 8) Final Test Evaluation ───────────────────────────────────────\n",
    "gnn.load_state_dict(torch.load('best_gnn.pth'))\n",
    "predictor.load_state_dict(torch.load('best_predictor.pth'))\n",
    "test_metrics = evaluate(test_data)\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"AUC: {test_metrics['auc']:.4f} | Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {test_metrics['recall']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "print(f\"Optimal Threshold: {test_metrics['threshold']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model after training\n",
    "torch.save(gnn.state_dict(), GNN_MODEL_SAVE_PATH)\n",
    "torch.save(predictor.state_dict(), PREDICTOR_MODEL_SAVE_PATH)\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate model architecture\n",
    "hidden_dim = 128\n",
    "gnn = HeteroGraphSAGE(hidden_dim)\n",
    "predictor = LinkPredictor(hidden_dim)\n",
    "\n",
    "# Load saved weights with map_location set to 'cpu'\n",
    "gnn.load_state_dict(torch.load(GNN_MODEL_SAVE_PATH, map_location=torch.device('cpu')))\n",
    "predictor.load_state_dict(torch.load(PREDICTOR_MODEL_SAVE_PATH, map_location=torch.device('cpu')))\n",
    "\n",
    "# Move models to desired device (optional)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "gnn = gnn.to(device)\n",
    "predictor = predictor.to(device)\n",
    "\n",
    "# Set models to evaluation mode for inference\n",
    "gnn.eval()\n",
    "predictor.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn.train()\n",
    "predictor.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bab9d",
   "metadata": {},
   "source": [
    "# 10. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62756a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acee341e",
   "metadata": {},
   "source": [
    "# ✅ 1. Top-K Recommendations for a User\n",
    "\n",
    "Recommend top k items for a given user based on predicted interaction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def recommend(user_id, gnn_model, predictor_model, data, k=10):\n",
    "    \"\"\"\n",
    "    Recommend top-k items for a given user based on learned embeddings.\n",
    "    \n",
    "    Args:\n",
    "        user_id (int): ID of the user\n",
    "        gnn_model: Trained heterogeneous GNN model (HeteroGraphSAGE)\n",
    "        predictor_model: Link predictor (MLP)\n",
    "        data: HeteroData object (val or test split)\n",
    "        k (int): Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "        list: Top-k item IDs recommended for the user\n",
    "    \"\"\"\n",
    "    gnn_model.eval()\n",
    "    predictor_model.eval()\n",
    "\n",
    "    # Get embeddings for all nodes\n",
    "    emb = gnn_model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "    # Get user embedding\n",
    "    user_emb = emb['user'][user_id].unsqueeze(0)  # shape: [1, hidden_dim]\n",
    "\n",
    "    # Get all item embeddings\n",
    "    item_embs = emb['item']  # shape: [num_items, hidden_dim]\n",
    "\n",
    "    # Repeat user embedding to match item_embs size\n",
    "    user_embs = user_emb.expand(item_embs.size(0), -1)\n",
    "\n",
    "    # Predict scores for all items\n",
    "    scores = predictor_model(user_embs, item_embs).cpu().numpy()\n",
    "\n",
    "    # Exclude already interacted items\n",
    "    interacted_items = data['user', 'rates', 'item'].edge_index[1][\n",
    "        data['user', 'rates', 'item'].edge_index[0] == user_id\n",
    "    ].cpu().numpy()\n",
    "\n",
    "    # Mask out interacted items\n",
    "    scores[interacted_items] = -np.inf\n",
    "\n",
    "    # Get top-k item indices\n",
    "    top_k_item_ids = np.argpartition(scores, -k)[-k:]\n",
    "    top_k_item_ids = top_k_item_ids[np.argsort(-scores[top_k_item_ids])]  # Sort descending\n",
    "\n",
    "    return top_k_item_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4afe073",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0\n",
    "recommended_items = recommend(user_id, gnn, predictor, test_data, k=5)\n",
    "print(f\"Top-5 Recommended Items for User {user_id}: {recommended_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41eaa6",
   "metadata": {},
   "source": [
    "# 2. Item-to-Item Recommendations (Similar Items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def similar_items(item_id, gnn_model, data, k=5):\n",
    "    gnn_model.eval()\n",
    "    emb = gnn_model(data.x_dict, data.edge_index_dict)['item']\n",
    "    item_emb = emb[item_id].unsqueeze(0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    sim = F.cosine_similarity(item_emb, emb).cpu().numpy()\n",
    "    sim[item_id] = -np.inf  # Exclude self\n",
    "    \n",
    "    # Top-k most similar items\n",
    "    top_k = np.argpartition(sim, -k)[-k:]\n",
    "    return top_k[np.argsort(-sim[top_k])].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_items(42, gnn, test_data, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad10e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
