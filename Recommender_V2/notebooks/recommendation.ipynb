{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53039982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3280433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    auc\n",
    ")\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, Linear\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from settings import (\n",
    "    META_DATA_PATH,\n",
    "    REVIEWS_DATA_PATH,\n",
    "    GRAPH_FULL_PATH,\n",
    "    GRAPH_TRAIN_PATH,\n",
    "    GRAPH_VAL_PATH,\n",
    "    GRAPH_TEST_PATH,\n",
    "    IMAGES_DIR,\n",
    "    ENCODER_USER,\n",
    "    ENCODER_ITEM, \n",
    "    ENCODER_CATEGORY,\n",
    "    ENCODER_BRAND,\n",
    "    ENCODER_COLOR,\n",
    "    ENCODER_SCALER,\n",
    "    MAPPING_USER,\n",
    "    MAPPING_ITEM,\n",
    "    GNN_MODEL_SAVE_PATH,\n",
    "    ITEM_FEATURE_PREPROCESSOR,\n",
    "    PREDICTOR_MODEL_SAVE_PATH,\n",
    "    REVERSED_MAPPING_ITEM, \n",
    "    CLEANED_META_DATA_PATH\n",
    "\n",
    ")\n",
    "\n",
    "# Configure paths\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, os.pardir, os.pardir))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df24a6",
   "metadata": {},
   "source": [
    "# ðŸ§® 1. Data Encoding and Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bb2e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "meta_df = pd.read_csv(META_DATA_PATH)\n",
    "reviews_df = pd.read_csv(REVIEWS_DATA_PATH)\n",
    "\n",
    "# Sample reviews for consistency\n",
    "reviews_df = reviews_df.sample(n=2000, random_state=42)\n",
    "filtered_item_ids = reviews_df['parent_asin'].unique()\n",
    "filtered_meta_df = meta_df[meta_df['parent_asin'].isin(filtered_item_ids)]\n",
    "\n",
    "# Encode user/item IDs\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# Encode and map\n",
    "reviews_df['user_idx'] = user_encoder.fit_transform(reviews_df['user_id'])\n",
    "reviews_df['item_idx'] = item_encoder.fit_transform(reviews_df['parent_asin'])\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(user_encoder, ENCODER_USER)\n",
    "joblib.dump(item_encoder, ENCODER_ITEM)\n",
    "\n",
    "# Build and save mappings\n",
    "user_id_map = dict(zip(reviews_df['user_id'], reviews_df['user_idx']))\n",
    "item_id_map = dict(zip(reviews_df['parent_asin'], reviews_df['item_idx']))\n",
    "\n",
    "# Save user/item mappings\n",
    "with open(MAPPING_USER, 'w') as f:\n",
    "    json.dump({str(k): int(v) for k, v in user_id_map.items()}, f)\n",
    "\n",
    "with open(MAPPING_ITEM, 'w') as f:\n",
    "    json.dump({str(k): int(v) for k, v in item_id_map.items()}, f)\n",
    "\n",
    "# Build reverse mapping\n",
    "id_to_item = {int(v): k for k, v in item_id_map.items()}\n",
    "with open(REVERSED_MAPPING_ITEM, 'w') as f:\n",
    "    json.dump(id_to_item, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build and save mappings\n",
    "user_id_map = dict(zip(reviews_df['user_id'], reviews_df['user_idx']))\n",
    "item_id_map = dict(zip(reviews_df['parent_asin'], reviews_df['item_idx']))\n",
    "\n",
    "# Save user/item mappings\n",
    "with open(MAPPING_USER, 'w') as f:\n",
    "    json.dump({str(k): int(v) for k, v in user_id_map.items()}, f)\n",
    "\n",
    "with open(MAPPING_ITEM, 'w') as f:\n",
    "    json.dump({str(k): int(v) for k, v in item_id_map.items()}, f)\n",
    "\n",
    "# Build reverse mapping\n",
    "id_to_item = {int(v): k for k, v in item_id_map.items()}\n",
    "with open(REVERSED_MAPPING_ITEM, 'w') as f:\n",
    "    json.dump(id_to_item, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c8fae4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((131, 15), (1858,), (2000, 13))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_meta_df.shape, filtered_item_ids.shape, reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a2af85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>price</th>\n",
       "      <th>store</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_description_items</th>\n",
       "      <th>first_image</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>date_first_available</th>\n",
       "      <th>primary_category</th>\n",
       "      <th>rating_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Computers</td>\n",
       "      <td>KHOMO - iPad 2 3 and 4 Generation Case - DUAL ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2745</td>\n",
       "      <td>11.95</td>\n",
       "      <td>Khomo</td>\n",
       "      <td>B06XKRXLDR</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31+mP+y8Uo...</td>\n",
       "      <td>Khomo</td>\n",
       "      <td>Black</td>\n",
       "      <td>2011-05-13</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>All Electronics</td>\n",
       "      <td>Charger for MacBook Pro 10FT, 96W USB C Charge...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2141</td>\n",
       "      <td>35.99</td>\n",
       "      <td>Ifeart</td>\n",
       "      <td>B07WZT643Q</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/21QlbdFXAG...</td>\n",
       "      <td>Ifeart</td>\n",
       "      <td>White</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Computers</td>\n",
       "      <td>InstallerParts (10 Pack Ethernet Cable CAT6 Ca...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>632</td>\n",
       "      <td>22.49</td>\n",
       "      <td>Installerparts</td>\n",
       "      <td>B07G3K1PQL</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41hcVGak0a...</td>\n",
       "      <td>Installerparts</td>\n",
       "      <td>Black</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Tools &amp; Home Improvement</td>\n",
       "      <td>GE 44848 65-Watt Plant Light Reflector R30 Lig...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>289</td>\n",
       "      <td>19.99</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>B0002YXGSC</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41SfEFwZPE...</td>\n",
       "      <td>General Electric</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2007-06-27</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Home Audio &amp; Theater</td>\n",
       "      <td>Cmple - 2 RCA to 2 RCA Cables 100ft, Male to M...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1297</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Cmple</td>\n",
       "      <td>B07BKZVWDM</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>https://m.media-amazon.com/images/I/413CwwAn+O...</td>\n",
       "      <td>Cmple</td>\n",
       "      <td>Black</td>\n",
       "      <td>2011-04-14</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                main_category  \\\n",
       "21                  Computers   \n",
       "35            All Electronics   \n",
       "211                 Computers   \n",
       "263  Tools & Home Improvement   \n",
       "315      Home Audio & Theater   \n",
       "\n",
       "                                                 title  average_rating  \\\n",
       "21   KHOMO - iPad 2 3 and 4 Generation Case - DUAL ...             4.5   \n",
       "35   Charger for MacBook Pro 10FT, 96W USB C Charge...             4.5   \n",
       "211  InstallerParts (10 Pack Ethernet Cable CAT6 Ca...             4.8   \n",
       "263  GE 44848 65-Watt Plant Light Reflector R30 Lig...             4.5   \n",
       "315  Cmple - 2 RCA to 2 RCA Cables 100ft, Male to M...             4.5   \n",
       "\n",
       "     rating_number  price             store parent_asin  n_features  \\\n",
       "21            2745  11.95             Khomo  B06XKRXLDR           5   \n",
       "35            2141  35.99            Ifeart  B07WZT643Q           5   \n",
       "211            632  22.49    Installerparts  B07G3K1PQL           5   \n",
       "263            289  19.99  General Electric  B0002YXGSC           5   \n",
       "315           1297  18.99             Cmple  B07BKZVWDM           5   \n",
       "\n",
       "     n_description_items                                        first_image  \\\n",
       "21                     1  https://m.media-amazon.com/images/I/31+mP+y8Uo...   \n",
       "35                     0  https://m.media-amazon.com/images/I/21QlbdFXAG...   \n",
       "211                    0  https://m.media-amazon.com/images/I/41hcVGak0a...   \n",
       "263                    2  https://m.media-amazon.com/images/I/41SfEFwZPE...   \n",
       "315                    1  https://m.media-amazon.com/images/I/413CwwAn+O...   \n",
       "\n",
       "                brand    color date_first_available primary_category  \\\n",
       "21              Khomo    Black           2011-05-13      Electronics   \n",
       "35             Ifeart    White           2019-09-23      Electronics   \n",
       "211    Installerparts    Black           2017-04-07      Electronics   \n",
       "263  General Electric  Unknown           2007-06-27      Electronics   \n",
       "315             Cmple    Black           2011-04-14      Electronics   \n",
       "\n",
       "    rating_bin  \n",
       "21      Medium  \n",
       "35      Medium  \n",
       "211       High  \n",
       "263     Medium  \n",
       "315     Medium  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_meta_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1227de4",
   "metadata": {},
   "source": [
    "# ðŸ“¦ 2. Feature Engineering and Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d57b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw item features shape: (131, 180)\n",
      "Successfully mapped 2/1858 item features\n",
      "Final item features shape: torch.Size([1858, 64])\n",
      "Graph: HeteroData(\n",
      "  user={ x=[1997, 64] },\n",
      "  item={ x=[1858, 64] },\n",
      "  (user, rates, item)={\n",
      "    edge_index=[2, 2000],\n",
      "    edge_weight=[2000],\n",
      "  },\n",
      "  (item, rev_rates, user)={\n",
      "    edge_index=[2, 2000],\n",
      "    edge_weight=[2000],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get correct dimensions\n",
    "num_items = reviews_df['item_idx'].nunique()  # Should be 960\n",
    "feature_dim = 64\n",
    "\n",
    "# Define feature groups\n",
    "numerical_features = ['price', 'average_rating', 'rating_number', 'n_features', 'n_description_items']\n",
    "categorical_features = ['main_category', 'brand', 'color']\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "        ]), categorical_features)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0\n",
    ")\n",
    "\n",
    "# Fit on available meta_df data\n",
    "meta_df_clean = filtered_meta_df.drop_duplicates('parent_asin')\n",
    "meta_features = preprocessor.fit_transform(meta_df_clean[numerical_features + categorical_features])\n",
    "print(f\"Raw item features shape: {meta_features.shape}\")\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(preprocessor, ITEM_FEATURE_PREPROCESSOR)\n",
    "\n",
    "# Convert to tensor\n",
    "if hasattr(meta_features, 'toarray'):\n",
    "    meta_array = meta_features.toarray()\n",
    "else:\n",
    "    meta_array = meta_features\n",
    "\n",
    "meta_tensor = torch.tensor(meta_array.astype(np.float32), dtype=torch.float32)\n",
    "\n",
    "# Create projection layer\n",
    "if meta_tensor.size(1) != feature_dim:\n",
    "    projection_layer = torch.nn.Linear(meta_tensor.size(1), feature_dim)\n",
    "    projected_meta = projection_layer(meta_tensor)  # Now [76, 64]\n",
    "else:\n",
    "    projected_meta = meta_tensor\n",
    "\n",
    "# Build full item features\n",
    "item_features = torch.zeros(num_items, feature_dim)\n",
    "valid_count = 0\n",
    "\n",
    "# Map meta_df features to item indices\n",
    "for asin, idx in item_id_map.items():\n",
    "    if asin in meta_df_clean['parent_asin'].values:\n",
    "        try:\n",
    "            row_idx = meta_df_clean[meta_df_clean['parent_asin'] == asin].index[0]\n",
    "            item_features[idx] = projected_meta[row_idx]\n",
    "            valid_count += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "print(f\"Successfully mapped {valid_count}/{num_items} item features\")\n",
    "\n",
    "# Build edge index\n",
    "edge_index = torch.tensor([\n",
    "    reviews_df['user_idx'].values,\n",
    "    reviews_df['item_idx'].values\n",
    "], dtype=torch.long)\n",
    "\n",
    "ratings = torch.tensor(reviews_df['rating'].values, dtype=torch.float)\n",
    "\n",
    "# Build HeteroData object\n",
    "data = HeteroData()\n",
    "data['user'].x = torch.randn(reviews_df['user_idx'].nunique(), feature_dim)\n",
    "data['item'].x = item_features\n",
    "data['user', 'rates', 'item'].edge_index = edge_index\n",
    "data['user', 'rates', 'item'].edge_weight = ratings\n",
    "data['item', 'rev_rates', 'user'].edge_index = edge_index.flip(0)\n",
    "data['item', 'rev_rates', 'user'].edge_weight = ratings\n",
    "\n",
    "print(f\"Final item features shape: {data['item'].x.shape}\")\n",
    "print(f\"Graph: {data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790188bc",
   "metadata": {},
   "source": [
    "# ðŸ”€ 3. Graph Splitting and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6293ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Apply RandomLinkSplit\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=[('user', 'rates', 'item')],\n",
    "    rev_edge_types=[('item', 'rev_rates', 'user')]\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "# Save graphs\n",
    "torch.save(data, GRAPH_FULL_PATH)\n",
    "torch.save(train_data, GRAPH_TRAIN_PATH)\n",
    "torch.save(val_data, GRAPH_VAL_PATH)\n",
    "torch.save(test_data, GRAPH_TEST_PATH)\n",
    "\n",
    "print(\"Graphs saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced94cdd",
   "metadata": {},
   "source": [
    "# ðŸ§± 4. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "996bb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGraphSAGE(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('user', 'rates', 'item'): SAGEConv((-1, -1), hidden_dim),\n",
    "            ('item', 'rev_rates', 'user'): SAGEConv((-1, -1), hidden_dim)\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        self.conv2 = HeteroConv({\n",
    "            ('user', 'rates', 'item'): SAGEConv(hidden_dim, hidden_dim),\n",
    "            ('item', 'rev_rates', 'user'): SAGEConv(hidden_dim, hidden_dim)\n",
    "        }, aggr='mean')\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.bn1(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: F.leaky_relu(x) for key, x in x_dict.items()}\n",
    "        x_dict = {key: self.dropout(x) for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        x_dict = {key: self.bn2(x) for key, x in x_dict.items()}\n",
    "        return x_dict\n",
    "\n",
    "class LinkPredictor(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, src, dst):\n",
    "        return self.mlp(torch.cat([src, dst], dim=-1)).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe84b3",
   "metadata": {},
   "source": [
    "# ðŸ”§ 5. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7989c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdalrhman/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Move data to device\n",
    "train_data, val_data, test_data = [d.to(device) for d in [train_data, val_data, test_data]]\n",
    "\n",
    "# Initialize models\n",
    "gnn = HeteroGraphSAGE(hidden_dim=128).to(device)\n",
    "predictor = LinkPredictor(hidden_dim=128).to(device)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': gnn.parameters(), 'lr': 1e-3},\n",
    "    {'params': predictor.parameters(), 'lr': 5e-4}\n",
    "], weight_decay=1e-5)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Load item_id_map for negative sampling\n",
    "def load_mapping(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "item_id_map = load_mapping(MAPPING_ITEM)\n",
    "num_items = len(item_id_map)  # 960"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de93995",
   "metadata": {},
   "source": [
    "# ðŸ§ª 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af4a4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data, neg_ratio=5):\n",
    "    gnn.train()\n",
    "    predictor.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    emb = gnn(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Positive edges\n",
    "    edge_index = data['user', 'rates', 'item'].edge_index\n",
    "    src, dst = edge_index[0], edge_index[1]\n",
    "    pos_pred = predictor(emb['user'][src], emb['item'][dst])\n",
    "    \n",
    "    # Negative sampling\n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in src.unique().cpu().tolist():\n",
    "        seen = dst[src == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*neg_ratio,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "    \n",
    "    if not neg_src:\n",
    "        return 0.0\n",
    "        \n",
    "    neg_pred = predictor(\n",
    "        emb['user'][torch.cat(neg_src)],\n",
    "        emb['item'][torch.cat(neg_dst)]\n",
    "    )\n",
    "    \n",
    "    # Loss calculation\n",
    "    loss = F.binary_cross_entropy_with_logits(\n",
    "        torch.cat([pos_pred, neg_pred]),\n",
    "        torch.cat([torch.ones_like(pos_pred), torch.zeros_like(neg_pred)])\n",
    "    )\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(data):\n",
    "    gnn.eval()\n",
    "    predictor.eval()\n",
    "    emb = gnn(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    edge_index = data['user', 'rates', 'item'].edge_index\n",
    "    src, dst = edge_index[0], edge_index[1]\n",
    "    \n",
    "    # Get positive scores\n",
    "    pos_pred = predictor(emb['user'][src], emb['item'][dst])\n",
    "    pos_labels = torch.ones(len(pos_pred))\n",
    "    \n",
    "    # Generate negatives\n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in src.unique().cpu().tolist():\n",
    "        seen = dst[src == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*5,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "    \n",
    "    if not neg_src:\n",
    "        return {\n",
    "            'auc': 0.5, 'f1': 0.0,\n",
    "            'precision': 0.0, 'recall': 0.0,\n",
    "            'threshold': 0.5\n",
    "        }\n",
    "    \n",
    "    neg_pred = predictor(\n",
    "        emb['user'][torch.cat(neg_src)],\n",
    "        emb['item'][torch.cat(neg_dst)]\n",
    "    )\n",
    "    neg_labels = torch.zeros(len(neg_pred))\n",
    "    \n",
    "    # Combine and compute metrics\n",
    "    scores = torch.cat([pos_pred, neg_pred]).cpu().numpy()\n",
    "    labels = torch.cat([pos_labels, neg_labels]).cpu().numpy()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(labels, scores)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'precision': precisions[best_idx],\n",
    "        'recall': recalls[best_idx],\n",
    "        'f1': f1_scores[best_idx],\n",
    "        'threshold': thresholds[best_idx]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f77af",
   "metadata": {},
   "source": [
    "# ðŸš€ 7. Model Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fa15a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 0.6975 | Val AUC: 0.6071 | F1: 0.6874 | Prec: 0.5400 | Rec: 0.9456 | Threshold: 0.0465\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m501\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     val_metrics = evaluate(val_data)\n\u001b[32m     17\u001b[39m     scheduler.step(val_metrics[\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(data, neg_ratio)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Loss calculation\u001b[39;00m\n\u001b[32m     33\u001b[39m loss = F.binary_cross_entropy_with_logits(\n\u001b[32m     34\u001b[39m     torch.cat([pos_pred, neg_pred]),\n\u001b[32m     35\u001b[39m     torch.cat([torch.ones_like(pos_pred), torch.zeros_like(neg_pred)])\n\u001b[32m     36\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m optimizer.step()\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Graduation Project/AiStore/venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# Initialize tracking\n",
    "epochs_list = []\n",
    "losses_list = []\n",
    "aucs_list = []\n",
    "f1s_list = []\n",
    "precisions_list = []\n",
    "recalls_list = []\n",
    "thresholds_list = []\n",
    "\n",
    "best_f1 = 0.0\n",
    "patience = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 501):\n",
    "    loss = train_epoch(train_data)\n",
    "    val_metrics = evaluate(val_data)\n",
    "    scheduler.step(val_metrics['f1'])\n",
    "    \n",
    "    # Log metrics\n",
    "    epochs_list.append(epoch)\n",
    "    losses_list.append(loss)\n",
    "    aucs_list.append(val_metrics['auc'])\n",
    "    f1s_list.append(val_metrics['f1'])\n",
    "    precisions_list.append(val_metrics['precision'])\n",
    "    recalls_list.append(val_metrics['recall'])\n",
    "    thresholds_list.append(val_metrics['threshold'])\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | \"\n",
    "          f\"Val AUC: {val_metrics['auc']:.4f} | F1: {val_metrics['f1']:.4f} | \"\n",
    "          f\"Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f} | \"\n",
    "          f\"Threshold: {val_metrics['threshold']:.4f}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_metrics['f1'] > best_f1:\n",
    "        best_f1 = val_metrics['f1']\n",
    "        torch.save(gnn.state_dict(), GNN_MODEL_SAVE_PATH)\n",
    "        torch.save(predictor.state_dict(), PREDICTOR_MODEL_SAVE_PATH)\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 20:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b5c8ea",
   "metadata": {},
   "source": [
    "# ðŸ“Š 8. Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training metrics\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_list, losses_list, label=\"Train Loss\", color='red')\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "# AUC\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_list, aucs_list, label=\"Val AUC\", color='green')\n",
    "plt.title(\"Validation AUC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "# F1 Score\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs_list, f1s_list, label=\"Val F1\", color='blue')\n",
    "plt.title(\"Validation F1 Score\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"F1\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Precision & Recall\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs_list, precisions_list, label=\"Precision\", color='orange')\n",
    "plt.plot(epochs_list, recalls_list, label=\"Recall\", color='purple')\n",
    "plt.title(\"Precision & Recall\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(IMAGES_DIR)\n",
    "plt.savefig(os.path.join(IMAGES_DIR, 'model_evaluation.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80631d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_model():\n",
    "    gnn.load_state_dict(torch.load(GNN_MODEL_SAVE_PATH, map_location=device))\n",
    "    predictor.load_state_dict(torch.load(PREDICTOR_MODEL_SAVE_PATH, map_location=device))\n",
    "    test_metrics = evaluate(test_data)\n",
    "    \n",
    "    print(\"\\nTest Metrics:\")\n",
    "    print(f\"AUC: {test_metrics['auc']:.4f} | F1: {test_metrics['f1']:.4f}\")\n",
    "    print(f\"Precision: {test_metrics['precision']:.4f} | Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"Threshold: {test_metrics['threshold']:.4f}\")\n",
    "    \n",
    "    # Plot PR Curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    emb = gnn(test_data.x_dict, test_data.edge_index_dict)\n",
    "    edge_index = test_data['user', 'rates', 'item'].edge_index\n",
    "    pos_pred = predictor(emb['user'][edge_index[0]], emb['item'][edge_index[1]])\n",
    "    pos_labels = torch.ones(len(pos_pred))\n",
    "    \n",
    "    neg_src, neg_dst = [], []\n",
    "    for u in edge_index[0].unique().cpu().tolist():\n",
    "        seen = edge_index[1][edge_index[0] == u]\n",
    "        candidates = torch.randint(0, num_items, (len(seen)*5,), device=seen.device)\n",
    "        valid = ~torch.isin(candidates, seen)\n",
    "        sampled = candidates[valid][:len(seen)]\n",
    "        if len(sampled) > 0:\n",
    "            neg_src.append(torch.tensor([u]*len(sampled), device=device))\n",
    "            neg_dst.append(sampled)\n",
    "    \n",
    "    if neg_src:\n",
    "        neg_pred = predictor(\n",
    "            emb['user'][torch.cat(neg_src)],\n",
    "            emb['item'][torch.cat(neg_dst)]\n",
    "        )\n",
    "        neg_labels = torch.zeros(len(neg_pred))\n",
    "        scores = torch.cat([pos_pred, neg_pred]).cpu().numpy()\n",
    "        labels = torch.cat([pos_labels, neg_labels]).cpu().numpy()\n",
    "        \n",
    "        # PR Curve\n",
    "        precisions, recalls, thresholds = precision_recall_curve(labels, scores)\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recalls, precisions, label=f'PR Curve (AUC={auc(recalls, precisions):.4f})')\n",
    "        plt.plot([test_metrics['recall']], [test_metrics['precision']], \n",
    "                'ro', markersize=10, label='Best F1 Threshold')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title(\"Precision-Recall Curve on Test Set\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(IMAGES_DIR, 'pr_curve_test.png'))\n",
    "        plt.show()\n",
    "    \n",
    "    return test_metrics\n",
    "\n",
    "# Run final evaluation\n",
    "test_results = test_model()\n",
    "print(f\"Final Test Results: {test_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot threshold evolution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_list, thresholds_list, label=\"Optimal Threshold\", color='green')\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', label=\"Default Threshold\")\n",
    "plt.title(\"Threshold Calibration Over Training\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Threshold\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(IMAGES_DIR)\n",
    "plt.savefig(os.path.join(IMAGES_DIR, 'threhold_plot.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31883bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "torch.save(gnn.state_dict(), GNN_MODEL_SAVE_PATH)\n",
    "torch.save(predictor.state_dict(), PREDICTOR_MODEL_SAVE_PATH)\n",
    "\n",
    "# Save preprocessor and feature encoders\n",
    "cat_encoder = preprocessor.named_transformers_['cat'].named_steps['encoder']\n",
    "num_scaler = preprocessor.named_transformers_['num'].named_steps['scaler']\n",
    "joblib.dump(cat_encoder, ENCODER_CATEGORY)\n",
    "joblib.dump(num_scaler, ENCODER_SCALER)\n",
    "joblib.dump(meta_df_clean, CLEANED_META_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c70e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b546be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807420de",
   "metadata": {},
   "source": [
    "# âœ… Final Recommender Function with Real ASINs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mappings():\n",
    "    # Verify files exist\n",
    "    for path in [MAPPING_USER, MAPPING_ITEM, REVERSED_MAPPING_ITEM]:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Mapping file not found: {path}\")\n",
    "    \n",
    "    # Load mappings\n",
    "    with open(MAPPING_USER, 'r') as f:\n",
    "        user_id_map = json.load(f)\n",
    "    \n",
    "    with open(MAPPING_ITEM, 'r') as f:\n",
    "        item_id_map = json.load(f)\n",
    "    \n",
    "    with open(REVERSED_MAPPING_ITEM, 'r') as f:\n",
    "        id_to_item = json.load(f)\n",
    "    \n",
    "    # Convert keys to correct types\n",
    "    return {\n",
    "        'user_id_map': {str(k): int(v) for k, v in user_id_map.items()},\n",
    "        'item_id_map': {str(k): int(v) for k, v in item_id_map.items()},\n",
    "        'id_to_item': {int(k): str(v) for k, v in id_to_item.items()}\n",
    "    }\n",
    "\n",
    "# Load mappings\n",
    "mappings = load_mappings()\n",
    "user_id_map = mappings['user_id_map']\n",
    "item_id_map = mappings['item_id_map']\n",
    "id_to_item = mappings['id_to_item']\n",
    "user_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full graph\n",
    "full_data = torch.load(GRAPH_FULL_PATH, weights_only=False, map_location=device)\n",
    "\n",
    "# Load trained models\n",
    "gnn = HeteroGraphSAGE(hidden_dim=128).to(device)\n",
    "predictor = LinkPredictor(hidden_dim=128).to(device)\n",
    "\n",
    "gnn.load_state_dict(torch.load(GNN_MODEL_SAVE_PATH, map_location=device))\n",
    "predictor.load_state_dict(torch.load(PREDICTOR_MODEL_SAVE_PATH, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def recommend_top_k(user_id, k=5):\n",
    "    \"\"\"\n",
    "    Recommend top-k products for a given user ID\n",
    "    \n",
    "    Args:\n",
    "        user_id (str): Original user ID\n",
    "        k (int): Number of recommendations\n",
    "    \n",
    "    Returns:\n",
    "        list: List of recommended ASINs\n",
    "    \"\"\"\n",
    "    # Validate user exists in mapping\n",
    "    if user_id not in user_id_map:\n",
    "        raise ValueError(f\"User ID '{user_id}' not found in mappings\")\n",
    "    \n",
    "    # Get model indices\n",
    "    user_idx = int(user_id_map[user_id])\n",
    "    \n",
    "    # Get embeddings\n",
    "    emb = gnn(full_data.x_dict, full_data.edge_index_dict)\n",
    "    \n",
    "    # Get user embedding and expand for all items\n",
    "    user_emb = emb['user'][user_idx].unsqueeze(0).expand(full_data['item'].x.size(0), -1)\n",
    "    item_embs = emb['item']\n",
    "    \n",
    "    # Predict scores\n",
    "    scores = predictor(user_emb, item_embs).cpu().numpy()\n",
    "    \n",
    "    # Exclude already interacted items\n",
    "    edge_index = full_data['user', 'rates', 'item'].edge_index\n",
    "    interacted_items = edge_index[1][edge_index[0] == user_idx].cpu().numpy()\n",
    "    scores[interacted_items] = -np.inf\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_k_indices = np.argpartition(scores, -k)[-k:]\n",
    "    top_k_scores = scores[top_k_indices]\n",
    "    top_k_indices = top_k_indices[np.argsort(-top_k_scores)]\n",
    "    \n",
    "    # Map to ASINs\n",
    "    return [id_to_item.get(int(i), None) for i in top_k_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e53e65",
   "metadata": {},
   "source": [
    "# ðŸ“¦ Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0659b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    recommendations = recommend_top_k('AFCO6LEANZBTDWKI4BH6BO7H4PIA', k=5)\n",
    "    print(\"Recommended ASINs:\", recommendations)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543969be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_with_metadata(user_id, k=5):\n",
    "    recommended = recommend_top_k(user_id, k=k)\n",
    "    return meta_df[meta_df['parent_asin'].isin(recommended)][[\n",
    "        'parent_asin', 'title', 'price', 'average_rating', 'main_category'\n",
    "    ]].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended = recommend_top_k('AFCO6LEANZBTDWKI4BH6BO7H4PIA', k=5)\n",
    "print(\"Raw Recommended ASINs:\", recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff281208",
   "metadata": {},
   "source": [
    "# âœ… Load `meta_df_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c35d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original meta_df\n",
    "meta_df = pd.read_csv(META_DATA_PATH)\n",
    "\n",
    "# Reapply filtering and deduplication\n",
    "filtered_item_ids = reviews_df['parent_asin'].unique()\n",
    "meta_df_clean = meta_df[meta_df['parent_asin'].isin(filtered_item_ids)].drop_duplicates('parent_asin')\n",
    "\n",
    "# Save as CSV (recommended for safety)\n",
    "# meta_df_clean.to_csv(CLEANED_META_DATA_PATH, index=False)\n",
    "\n",
    "# Or save as pickle (ensure binary mode)\n",
    "meta_df_clean.to_pickle(CLEANED_META_DATA_PATH)\n",
    "loaded_meta_df_clean = pd.read_pickle(CLEANED_META_DATA_PATH)\n",
    "loaded_meta_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep ASINs that exist in meta_df_clean\n",
    "valid_recommended = [asin for asin in recommended if asin in loaded_meta_df_clean['parent_asin'].values]\n",
    "\n",
    "print(f\"Valid ASINs found in meta_df_clean: {valid_recommended}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9021e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter meta_df_clean to only include valid ASINs\n",
    "recommended_products = loaded_meta_df_clean[loaded_meta_df_clean['parent_asin'].isin(valid_recommended)]\n",
    "\n",
    "# Add a custom sort order based on original recommendation\n",
    "recommended_products['asin_order'] = pd.Categorical(\n",
    "    recommended_products['parent_asin'], \n",
    "    categories=valid_recommended,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Sort by recommendation order\n",
    "recommended_products = recommended_products.sort_values('asin_order').drop('asin_order', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show important product info\n",
    "print(recommended_products[[\n",
    "    'parent_asin', 'title', 'price', 'average_rating', \n",
    "    'main_category', 'brand', 'color'\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32611027",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = recommended_products.to_dict(orient='records')\n",
    "\n",
    "for p in product_list:\n",
    "    print(f\"ASIN: {p['parent_asin']}\")\n",
    "    print(f\"Title: {p['title']}\")\n",
    "    print(f\"Price: ${p['price']}\")\n",
    "    print(f\"Rating: {p['average_rating']} ({p['rating_number']} reviews)\")\n",
    "    print(f\"Category: {p['main_category']}\")\n",
    "    print(f\"Brand: {p['brand']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b99147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommended_products(recommended, meta_df_clean):\n",
    "    \"\"\"\n",
    "    Safely filter and reorder meta_df_clean based on recommended ASINs.\n",
    "    \n",
    "    Args:\n",
    "        recommended (list): List of ASINs from recommendation system\n",
    "        meta_df_clean (pd.DataFrame): Cleaned metadata with item features\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered and ordered DataFrame with product details\n",
    "    \"\"\"\n",
    "    # Step 1: Filter only valid ASINs that exist in meta_df_clean\n",
    "    valid_recommended = [asin for asin in recommended if asin in meta_df_clean['parent_asin'].values]\n",
    "    \n",
    "    # Step 2: Filter meta_df_clean for matching ASINs\n",
    "    filtered = meta_df_clean[meta_df_clean['parent_asin'].isin(valid_recommended)]\n",
    "    \n",
    "    # Step 3: Reorder to match recommendation order\n",
    "    filtered['asin_order'] = pd.Categorical(\n",
    "        filtered['parent_asin'], \n",
    "        categories=valid_recommended,\n",
    "        ordered=True\n",
    "    )\n",
    "    return filtered.sort_values('asin_order').drop('asin_order', axis=1)\n",
    "\n",
    "# Example usage\n",
    "recommended_products = get_recommended_products(recommended, loaded_meta_df_clean)\n",
    "recommended_products[['parent_asin', 'title', 'price', 'average_rating', 'main_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa8124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
